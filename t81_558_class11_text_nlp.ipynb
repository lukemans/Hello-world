{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T81-558: Applications of Deep Neural Networks\n",
    "**Class 11: Natural Language Processing and Speech Recognition**\n",
    "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), School of Engineering and Applied Science, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
    "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sources: DBPedia\n",
    "\n",
    "[DBPedia](http://wiki.dbpedia.org/) uses the data contained in [WikiPedia]() in database form.  The data in DBPedia can be queried in an SQL-like syntax named Protocol and RDF Query Language, or [SPARQL](https://en.wikipedia.org/wiki/SPARQL). \n",
    "\n",
    "For the text examples in this class we will use a sample of the DBPedia articles classified into 14 high level document classifications:\n",
    "\n",
    "* Company (1)\n",
    "* EducationalInstitution (2)\n",
    "* Artist (3)\n",
    "* Athlete (4)\n",
    "* OfficeHolder (5)\n",
    "* MeanOfTransportation (6)\n",
    "* Building (7)\n",
    "* NaturalPlace (8)\n",
    "* Village (9)\n",
    "* Animal (10)\n",
    "* Plant (11)\n",
    "* Album (12)\n",
    "* Film (13)\n",
    "* WrittenWork (14)\n",
    "\n",
    "The data files can be found at this [location](https://drive.google.com/drive/folders/0Bz8a_Dbh9Qhbfll6bVpmNUtUcFdjYmF2SEpmZUZUcVNiMUw1TWN6RDV3a0JHT3kxLVhVR2M).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow makes available several operators designed for text classification.\n",
    "\n",
    "* skflow.preprocessing.**ByteProcessor (doc_len)** - Turn a list of text strings into fixed length arrays (specified by doc_len) using integer ASCII values, for example \"ABC\" becomes [65, 66, 67, 0, 0] if the doc_len is 5.\n",
    "* skflow.ops.**one_hot_matrix** - One hot is the same as dummy variables. Expands multiple inputs into a cube, with dimensions [num_samples, input_size, num_samples].\n",
    "* skflow.ops.**split_squeeze** - Splits input on given dimension and then squeezes that dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 84, 104, 105, 115,  32], dtype=uint8), array([65, 66, 67,  0,  0], dtype=uint8), array([97, 98, 99,  0,  0], dtype=uint8)]\n"
     ]
    }
   ],
   "source": [
    "# Classifying Text Documents\n",
    "\n",
    "data = [\n",
    "    \"This is a test\",\n",
    "    \"ABC\",\n",
    "    \"abc\"\n",
    "]\n",
    "\n",
    "char_processor = skflow.preprocessing.ByteProcessor(5)\n",
    "\n",
    "z = list(char_processor.fit_transform(data))\n",
    "\n",
    "print(z)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn import metrics\n",
    "import pandas\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.models.rnn import rnn, rnn_cell\n",
    "from tensorflow.contrib import skflow\n",
    "\n",
    "### Training data\n",
    "\n",
    "# Download dbpedia_csv.tar.gz from\n",
    "# https://drive.google.com/folderview?id=0Bz8a_Dbh9Qhbfll6bVpmNUtUcFdjYmF2SEpmZUZUcVNiMUw1TWN6RDV3a0JHT3kxLVhVR2M\n",
    "# Unpack: tar -xvf dbpedia_csv.tar.gz\n",
    "\n",
    "path = \"./data/\"\n",
    "\n",
    "train = pandas.read_csv(os.path.join(path,\"train.csv\"), header=None)\n",
    "X_train, y_train = train[2], train[0]\n",
    "test = pandas.read_csv(os.path.join(path,\"test.csv\"), header=None)\n",
    "X_test, y_test = test[2], test[0]\n",
    "\n",
    "### Process vocabulary\n",
    "\n",
    "MAX_DOCUMENT_LENGTH = 100\n",
    "\n",
    "char_processor = skflow.preprocessing.ByteProcessor(MAX_DOCUMENT_LENGTH)\n",
    "X_train = np.array(list(char_processor.fit_transform(X_train)))\n",
    "X_test = np.array(list(char_processor.transform(X_test)))\n",
    "\n",
    "### Models\n",
    "\n",
    "HIDDEN_SIZE = 20\n",
    "\n",
    "def char_rnn_model(X, y):\n",
    "    byte_list = skflow.ops.one_hot_matrix(X, 256)\n",
    "    byte_list = skflow.ops.split_squeeze(1, MAX_DOCUMENT_LENGTH, byte_list)\n",
    "    cell = rnn_cell.GRUCell(HIDDEN_SIZE)\n",
    "    _, encoding = rnn.rnn(cell, byte_list, dtype=tf.float32)\n",
    "    return skflow.models.logistic_regression(encoding, y)\n",
    "\n",
    "classifier = skflow.TensorFlowEstimator(model_fn=char_rnn_model, n_classes=15,\n",
    "    steps=1000, optimizer='Adam', learning_rate=0.01, continue_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #99, avg. train loss: 2.68226\n",
      "Step #199, avg. train loss: 2.42822\n",
      "Step #299, avg. train loss: 1.94456\n",
      "Step #399, avg. train loss: 1.62389\n",
      "Step #499, avg. train loss: 1.38159\n",
      "Step #599, avg. train loss: 1.22085\n",
      "Step #699, avg. train loss: 1.15357\n",
      "Step #799, avg. train loss: 0.99735\n",
      "Step #899, avg. train loss: 0.96319\n",
      "Step #999, avg. train loss: 0.89216\n",
      "Accuracy: 0.687457\n",
      "Step #99, avg. train loss: 0.90357\n",
      "Step #199, avg. train loss: 0.84236\n",
      "Step #299, avg. train loss: 0.82514\n",
      "Step #399, avg. train loss: 0.76895\n",
      "Step #499, avg. train loss: 0.77610\n",
      "Step #599, avg. train loss: 0.74104\n",
      "Step #699, avg. train loss: 0.76284\n",
      "Step #799, avg. train loss: 0.69159\n",
      "Step #899, avg. train loss: 0.68181\n",
      "Step #999, avg. train loss: 0.66279\n",
      "Accuracy: 0.757243\n",
      "Step #99, avg. train loss: 0.68387\n",
      "Step #199, avg. train loss: 0.63289\n",
      "Step #299, avg. train loss: 0.63192\n",
      "Step #399, avg. train loss: 0.60658\n",
      "Step #499, avg. train loss: 0.61538\n",
      "Step #599, avg. train loss: 0.61461\n",
      "Step #699, avg. train loss: 0.64005\n",
      "Step #799, avg. train loss: 0.60081\n",
      "Step #899, avg. train loss: 0.56577\n",
      "Step #999, avg. train loss: 0.56744\n",
      "Accuracy: 0.793429\n",
      "Step #99, avg. train loss: 0.58773\n",
      "Step #199, avg. train loss: 0.55587\n",
      "Step #299, avg. train loss: 0.55278\n",
      "Step #399, avg. train loss: 0.53777\n",
      "Step #499, avg. train loss: 0.52889\n",
      "Step #599, avg. train loss: 0.54934\n",
      "Step #699, avg. train loss: 0.55660\n",
      "Step #799, avg. train loss: 0.53622\n",
      "Step #899, avg. train loss: 0.50377\n",
      "Step #999, avg. train loss: 0.51069\n",
      "Accuracy: 0.803243\n",
      "Step #99, avg. train loss: 0.54197\n",
      "Step #199, avg. train loss: 0.51163\n",
      "Step #299, avg. train loss: 0.50413\n",
      "Step #399, avg. train loss: 0.49793\n",
      "Step #499, avg. train loss: 0.46783\n",
      "Step #599, avg. train loss: 0.50312\n",
      "Step #699, avg. train loss: 0.50805\n",
      "Step #799, avg. train loss: 0.49145\n",
      "Step #899, avg. train loss: 0.46800\n",
      "Step #999, avg. train loss: 0.47253\n",
      "Accuracy: 0.807371\n"
     ]
    }
   ],
   "source": [
    "# Continuesly train for 1000 steps & predict on test set.\n",
    "for i in range(5):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    score = metrics.accuracy_score(y_test, classifier.predict(X_test))\n",
    "    print(\"Accuracy: %f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(560000, 100)\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:Tensor(\"OneHot:0\", shape=(560000, 100, 256), dtype=float32)\n",
      "100\n",
      "2:Tensor(\"Squeeze:0\", shape=(560000, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp = skflow.ops.one_hot_matrix(X_train, 256) \n",
    "print(\"1:{}\".format(temp))\n",
    "temp = skflow.ops.split_squeeze(1, MAX_DOCUMENT_LENGTH, temp)\n",
    "print(len(temp))\n",
    "print(\"2:{}\".format(temp[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# **Code below this point will not run in Data Scientist Workbench **\n",
    "\n",
    "The code below interfaces with your computer's microphone and speakers.  It will not run in Data Scientist Workbench.\n",
    "\n",
    "\n",
    "# Speech Recognition\n",
    "\n",
    "A very common use of LSTM and RNN's is [speech recognition](https://en.wikipedia.org/wiki/Speech_recognition).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Google Voice for Speech Recognition\n",
    "\n",
    "Google speech recognition makes use of [LSTM and some other technologies](https://research.googleblog.com/2015/08/the-neural-networks-behind-google-voice.html).\n",
    "\n",
    "See Google [Speech Recognition in action](https://www.google.com/intl/en/chrome/demos/speech.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something!\n",
      "You said: hello\n"
     ]
    }
   ],
   "source": [
    "# pip install SpeechRecognition\n",
    "# see this for PyAudio\n",
    "# pip install pyttsx\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "# NOTE: this example requires PyAudio because it uses the Microphone class\n",
    "\n",
    "import speech_recognition as sr\n",
    "\n",
    "# obtain audio from the microphone\n",
    "r = sr.Recognizer()\n",
    "with sr.Microphone() as source:\n",
    "    print(\"Say something!\")\n",
    "    audio = r.listen(source)\n",
    "\n",
    "# recognize speech using Google Speech Recognition\n",
    "try:\n",
    "    # for testing purposes, we're just using the default API key\n",
    "    # to use another API key, use `r.recognize_google(audio, key=\"GOOGLE_SPEECH_RECOGNITION_API_KEY\")`\n",
    "    # instead of `r.recognize_google(audio)`\n",
    "    str = r.recognize_google(audio)\n",
    "    print(\"You said: {}\".format(str))\n",
    "    os.system(\"say 'I believe you said: {}'\".format(str))\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Google Speech Recognition could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Text to Speech\n",
    "\n",
    "Challenges:\n",
    "\n",
    "* [Background Conversation](https://www.youtube.com/watch?v=IKB3Qiglyro&t=119s)\n",
    "* [Klingon](https://www.youtube.com/watch?v=ucO3heC-Ztw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The following code works on a Mac\n",
    "import os\n",
    "\n",
    "def say(s):\n",
    "    s = s.replace(\"'\",\"\")\n",
    "    os.system(\"say '{}'\".format(s))\n",
    "    \n",
    "say(\"Shall we play a game?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text to Speech and Speech Recognition\n",
    "\n",
    "\n",
    "Text to speech and speech recognition often go hand in hand.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You said: hola que tal como se Yama\n"
     ]
    }
   ],
   "source": [
    "# pip install SpeechRecognition\n",
    "# see this for PyAudio\n",
    "# pip install pyttsx\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "# NOTE: this example requires PyAudio because it uses the Microphone class\n",
    "\n",
    "import speech_recognition as sr\n",
    "import os\n",
    "\n",
    "def say(s):\n",
    "    s = s.replace(\"'\",\"\")\n",
    "    os.system(\"say '{}'\".format(s))\n",
    "\n",
    "# obtain audio from the microphone\n",
    "r = sr.Recognizer()\n",
    "with sr.Microphone() as source:\n",
    "    say(\"Hello there, please say something.\")\n",
    "    audio = r.listen(source)\n",
    "\n",
    "# recognize speech using Google Speech Recognition\n",
    "try:\n",
    "    # for testing purposes, we're just using the default API key\n",
    "    # to use another API key, use `r.recognize_google(audio, key=\"GOOGLE_SPEECH_RECOGNITION_API_KEY\")`\n",
    "    # instead of `r.recognize_google(audio)`\n",
    "    str = r.recognize_google(audio)\n",
    "    print(\"You said: {}\".format(str))\n",
    "    say(\"I think you said {}\".format(str))\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Google Speech Recognition could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliza Example\n",
    "\n",
    "[ELIZA](https://en.wikipedia.org/wiki/ELIZA) is an early natural language processing computer program created from 1964 to 1966 at the MIT Artificial Intelligence Laboratory by Joseph Weizenbaum.  The following code is based in an [Eliza Python Implementation by SureSmallThing](https://www.smallsurething.com/implementing-the-famous-eliza-chatbot-in-python/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: my mother hates me\n",
      "Eliza (computer): When your mother hates you, how do you feel?\n",
      "Human: I feel sad\n",
      "Eliza (computer): you feel sad.\n",
      "Human: yes I do do you feel sad\n",
      "Eliza (computer): OK, but can you elaborate a bit?\n",
      "No input, or could not understand audio.\n",
      "Human: quick\n",
      "Eliza (computer): Why do you say that quick?\n",
      "Human: quick\n",
      "Eliza (computer): quick.\n",
      "Human: quit\n",
      "Eliza (computer): Thank you for talking with me.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "import speech_recognition as sr\n",
    "import os\n",
    "\n",
    "reflections = {\n",
    "    \"am\": \"are\",\n",
    "    \"was\": \"were\",\n",
    "    \"i\": \"you\",\n",
    "    \"i'd\": \"you would\",\n",
    "    \"i've\": \"you have\",\n",
    "    \"i'll\": \"you will\",\n",
    "    \"my\": \"your\",\n",
    "    \"are\": \"am\",\n",
    "    \"you've\": \"I have\",\n",
    "    \"you'll\": \"I will\",\n",
    "    \"your\": \"my\",\n",
    "    \"yours\": \"mine\",\n",
    "    \"you\": \"me\",\n",
    "    \"me\": \"you\"\n",
    "}\n",
    "\n",
    "psychobabble = [\n",
    "    [r'i need (.*)',\n",
    "     [\"Why do you need {0}?\",\n",
    "      \"Would it really help you to get {0}?\",\n",
    "      \"Are you sure you need {0}?\"]],\n",
    "\n",
    "    [r'why don\\'?t you ([^\\?]*)\\??',\n",
    "     [\"Do you really think I don't {0}?\",\n",
    "      \"Perhaps eventually I will {0}.\",\n",
    "      \"Do you really want me to {0}?\"]],\n",
    "\n",
    "    [r'why can\\'?t I ([^\\?]*)\\??',\n",
    "     [\"Do you think you should be able to {0}?\",\n",
    "      \"If you could {0}, what would you do?\",\n",
    "      \"I don't know -- why can't you {0}?\",\n",
    "      \"Have you really tried?\"]],\n",
    "\n",
    "    [r'i can\\'?t (.*)',\n",
    "     [\"How do you know you can't {0}?\",\n",
    "      \"Perhaps you could {0} if you tried.\",\n",
    "      \"What would it take for you to {0}?\"]],\n",
    "\n",
    "    [r'i am (.*)',\n",
    "     [\"Did you come to me because you are {0}?\",\n",
    "      \"How long have you been {0}?\",\n",
    "      \"How do you feel about being {0}?\"]],\n",
    "\n",
    "    [r'i\\'?m (.*)',\n",
    "     [\"How does being {0} make you feel?\",\n",
    "      \"Do you enjoy being {0}?\",\n",
    "      \"Why do you tell me you're {0}?\",\n",
    "      \"Why do you think you're {0}?\"]],\n",
    "\n",
    "    [r'are you ([^\\?]*)\\??',\n",
    "     [\"Why does it matter whether I am {0}?\",\n",
    "      \"Would you prefer it if I were not {0}?\",\n",
    "      \"Perhaps you believe I am {0}.\",\n",
    "      \"I may be {0} -- what do you think?\"]],\n",
    "\n",
    "    [r'what (.*)',\n",
    "     [\"Why do you ask?\",\n",
    "      \"How would an answer to that help you?\",\n",
    "      \"What do you think?\"]],\n",
    "\n",
    "    [r'how (.*)',\n",
    "     [\"How do you suppose?\",\n",
    "      \"Perhaps you can answer your own question.\",\n",
    "      \"What is it you're really asking?\"]],\n",
    "\n",
    "    [r'because (.*)',\n",
    "     [\"Is that the real reason?\",\n",
    "      \"What other reasons come to mind?\",\n",
    "      \"Does that reason apply to anything else?\",\n",
    "      \"If {0}, what else must be true?\"]],\n",
    "\n",
    "    [r'(.*) sorry (.*)',\n",
    "     [\"There are many times when no apology is needed.\",\n",
    "      \"What feelings do you have when you apologize?\"]],\n",
    "\n",
    "    [r'hello(.*)',\n",
    "     [\"Hello... I'm glad you could drop by today.\",\n",
    "      \"Hi there... how are you today?\",\n",
    "      \"Hello, how are you feeling today?\"]],\n",
    "\n",
    "    [r'i think (.*)',\n",
    "     [\"Do you doubt {0}?\",\n",
    "      \"Do you really think so?\",\n",
    "      \"But you're not sure {0}?\"]],\n",
    "\n",
    "    [r'(.*) friend (.*)',\n",
    "     [\"Tell me more about your friends.\",\n",
    "      \"When you think of a friend, what comes to mind?\",\n",
    "      \"Why don't you tell me about a childhood friend?\"]],\n",
    "\n",
    "    [r'yes',\n",
    "     [\"You seem quite sure.\",\n",
    "      \"OK, but can you elaborate a bit?\"]],\n",
    "\n",
    "    [r'(.*) computer(.*)',\n",
    "     [\"Are you really talking about me?\",\n",
    "      \"Does it seem strange to talk to a computer?\",\n",
    "      \"How do computers make you feel?\",\n",
    "      \"Do you feel threatened by computers?\"]],\n",
    "\n",
    "    [r'is it (.*)',\n",
    "     [\"Do you think it is {0}?\",\n",
    "      \"Perhaps it's {0} -- what do you think?\",\n",
    "      \"If it were {0}, what would you do?\",\n",
    "      \"It could well be that {0}.\"]],\n",
    "\n",
    "    [r'it is (.*)',\n",
    "     [\"You seem very certain.\",\n",
    "      \"If I told you that it probably isn't {0}, what would you feel?\"]],\n",
    "\n",
    "    [r'can you ([^\\?]*)\\??',\n",
    "     [\"What makes you think I can't {0}?\",\n",
    "      \"If I could {0}, then what?\",\n",
    "      \"Why do you ask if I can {0}?\"]],\n",
    "\n",
    "    [r'can I ([^\\?]*)\\??',\n",
    "     [\"Perhaps you don't want to {0}.\",\n",
    "      \"Do you want to be able to {0}?\",\n",
    "      \"If you could {0}, would you?\"]],\n",
    "\n",
    "    [r'you are (.*)',\n",
    "     [\"Why do you think I am {0}?\",\n",
    "      \"Does it please you to think that I'm {0}?\",\n",
    "      \"Perhaps you would like me to be {0}.\",\n",
    "      \"Perhaps you're really talking about yourself?\"]],\n",
    "\n",
    "    [r'you\\'?re (.*)',\n",
    "     [\"Why do you say I am {0}?\",\n",
    "      \"Why do you think I am {0}?\",\n",
    "      \"Are we talking about you, or me?\"]],\n",
    "\n",
    "    [r'i don\\'?t (.*)',\n",
    "     [\"Don't you really {0}?\",\n",
    "      \"Why don't you {0}?\",\n",
    "      \"Do you want to {0}?\"]],\n",
    "\n",
    "    [r'i feel (.*)',\n",
    "     [\"Good, tell me more about these feelings.\",\n",
    "      \"Do you often feel {0}?\",\n",
    "      \"When do you usually feel {0}?\",\n",
    "      \"When you feel {0}, what do you do?\"]],\n",
    "\n",
    "    [r'i have (.*)',\n",
    "     [\"Why do you tell me that you've {0}?\",\n",
    "      \"Have you really {0}?\",\n",
    "      \"Now that you have {0}, what will you do next?\"]],\n",
    "\n",
    "    [r'i would (.*)',\n",
    "     [\"Could you explain why you would {0}?\",\n",
    "      \"Why would you {0}?\",\n",
    "      \"Who else knows that you would {0}?\"]],\n",
    "\n",
    "    [r'is there (.*)',\n",
    "     [\"Do you think there is {0}?\",\n",
    "      \"It's likely that there is {0}.\",\n",
    "      \"Would you like there to be {0}?\"]],\n",
    "\n",
    "    [r'my (.*)',\n",
    "     [\"I see, your {0}.\",\n",
    "      \"Why do you say that your {0}?\",\n",
    "      \"When your {0}, how do you feel?\"]],\n",
    "\n",
    "    [r'you (.*)',\n",
    "     [\"We should be discussing you, not me.\",\n",
    "      \"Why do you say that about me?\",\n",
    "      \"Why do you care whether I {0}?\"]],\n",
    "\n",
    "    [r'why (.*)',\n",
    "     [\"Why don't you tell me the reason why {0}?\",\n",
    "      \"Why do you think {0}?\"]],\n",
    "\n",
    "    [r'i want (.*)',\n",
    "     [\"What would it mean to you if you got {0}?\",\n",
    "      \"Why do you want {0}?\",\n",
    "      \"What would you do if you got {0}?\",\n",
    "      \"If you got {0}, then what would you do?\"]],\n",
    "\n",
    "    [r'(.*) mother(.*)',\n",
    "     [\"Tell me more about your mother.\",\n",
    "      \"What was your relationship with your mother like?\",\n",
    "      \"How do you feel about your mother?\",\n",
    "      \"How does this relate to your feelings today?\",\n",
    "      \"Good family relations are important.\"]],\n",
    "\n",
    "    [r'(.*) father(.*)',\n",
    "     [\"Tell me more about your father.\",\n",
    "      \"How did your father make you feel?\",\n",
    "      \"How do you feel about your father?\",\n",
    "      \"Does your relationship with your father relate to your feelings today?\",\n",
    "      \"Do you have trouble showing affection with your family?\"]],\n",
    "\n",
    "    [r'(.*) child(.*)',\n",
    "     [\"Did you have close friends as a child?\",\n",
    "      \"What is your favorite childhood memory?\",\n",
    "      \"Do you remember any dreams or nightmares from childhood?\",\n",
    "      \"Did the other children sometimes tease you?\",\n",
    "      \"How do you think your childhood experiences relate to your feelings today?\"]],\n",
    "\n",
    "    [r'(.*)\\?',\n",
    "     [\"Why do you ask that?\",\n",
    "      \"Please consider whether you can answer your own question.\",\n",
    "      \"Perhaps the answer lies within yourself?\",\n",
    "      \"Why don't you tell me?\"]],\n",
    "\n",
    "    [r'quit',\n",
    "     [\"Thank you for talking with me.\",\n",
    "      \"Good-bye.\",\n",
    "      \"Thank you, that will be $150.  Have a good day!\"]],\n",
    "\n",
    "    [r'(.*)',\n",
    "     [\"Please tell me more.\",\n",
    "      \"Let's change focus a bit... Tell me about your family.\",\n",
    "      \"Can you elaborate on that?\",\n",
    "      \"Why do you say that {0}?\",\n",
    "      \"I see.\",\n",
    "      \"Very interesting.\",\n",
    "      \"{0}.\",\n",
    "      \"I see.  And what does that tell you?\",\n",
    "      \"How does that make you feel?\",\n",
    "      \"How do you feel when you say that?\"]]\n",
    "]\n",
    "\n",
    "\n",
    "def reflect(fragment):\n",
    "    tokens = fragment.lower().split()\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token in reflections:\n",
    "            tokens[i] = reflections[token]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "\n",
    "def analyze(statement):\n",
    "    for pattern, responses in psychobabble:\n",
    "        match = re.match(pattern, statement.rstrip(\".!\"))\n",
    "        if match:\n",
    "            response = random.choice(responses)\n",
    "            return response.format(*[reflect(g) for g in match.groups()])\n",
    "\n",
    "def say(s):\n",
    "    s = s.replace(\"'\",\"\")\n",
    "    os.system(\"say '{}'\".format(s))\n",
    "\n",
    "def main():\n",
    "    say(\"Hello. How are you feeling today?\")\n",
    "\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            audio = r.listen(source)\n",
    "\n",
    "            # recognize speech using Google Speech Recognition\n",
    "            try:\n",
    "                # for testing purposes, we're just using the default API key\n",
    "                # to use another API key, use `r.recognize_google(audio, key=\"GOOGLE_SPEECH_RECOGNITION_API_KEY\")`\n",
    "                # instead of `r.recognize_google(audio)`\n",
    "                statement = r.recognize_google(audio)\n",
    "                print(\"Human: {}\".format(statement))\n",
    "                response = analyze(statement)\n",
    "\n",
    "                if statement.lower() == 'quit':\n",
    "                    done = True\n",
    "\n",
    "                print(\"Eliza (computer): {}\".format(response))\n",
    "                say(response)\n",
    "            except sr.UnknownValueError:\n",
    "                print(\"No input, or could not understand audio.\")\n",
    "            except sr.RequestError as e:\n",
    "                print(\"Error: Could not request results from Google Speech Recognition service; {0}\".format(e))\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat Bots\n",
    "\n",
    "Using the above code you can create your own primitive chat bots.  A some what famous video on Youtube from Cornell University shows what happens [when two chat bots converse](https://www.youtube.com/watch?v=WnzlbyTZsQY).  Other interesting chat bot type technology:\n",
    "\n",
    "* [CleverBot](http://www.cleverbot.com/)\n",
    "* [Computer Science Paper Generator](https://pdos.csail.mit.edu/archive/scigen/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More on LSTM\n",
    "\n",
    "* [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "* [LSTM Music](https://www.youtube.com/watch?v=0VTI1BBLydE)\n",
    "* [Natural Language Processing from Scratch](https://arxiv.org/abs/1103.0398)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
